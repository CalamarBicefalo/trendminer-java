/**
 * Copyright (c) 2011, The University of Southampton and the individual contributors.
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without modification,
 * are permitted provided that the following conditions are met:
 *
 *   * 	Redistributions of source code must retain the above copyright notice,
 * 	this list of conditions and the following disclaimer.
 *
 *   *	Redistributions in binary form must reproduce the above copyright notice,
 * 	this list of conditions and the following disclaimer in the documentation
 * 	and/or other materials provided with the distribution.
 *
 *   *	Neither the name of the University of Southampton nor the names of its
 * 	contributors may be used to endorse or promote products derived from this
 * 	software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
 * ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
 * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */
 
/*** 
	{ m -> 
		if (m['T'] == DOUBLE) {
			return (m['R'] == DOUBLE); 		
		}
		if (m['T'] == LONG) {
			return (m['R'] == DOUBLE);
		}
		return (m['R'] == FLOAT);
	}
***/

package org.openimaj.ml.clustering.kmeans.fast;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import java.util.Random;
import java.util.concurrent.Callable;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

import org.openimaj.citation.annotation.Reference;
import org.openimaj.citation.annotation.ReferenceType;
import org.openimaj.data.DataSource;
import org.openimaj.data.#T#ArrayBackedDataSource;
import org.openimaj.ml.clustering.SpatialClusterer;
import org.openimaj.ml.clustering.assignment.HardAssigner;
import org.openimaj.ml.clustering.assignment.hard.Approximate#T#EuclideanAssigner;
import org.openimaj.ml.clustering.assignment.hard.Exact#T#Assigner;
import org.openimaj.ml.clustering.#T#CentroidsResult;
import org.openimaj.knn.#T#NearestNeighbours;
import org.openimaj.knn.#T#NearestNeighboursExact;
import org.openimaj.knn.#T#NearestNeighboursProvider;
import org.openimaj.knn.approximate.#T#NearestNeighboursKDTree;

/**
 * An implementation of the Exact and Approximate KMeans algorithms.
 * <p>
 * Inspired by the implementation at: {@link "http://www.robots.ox.ac.uk/~vgg/software/fastcluster/"}
 * <p>
 * Clustering is initiated using a {@link Fast#T#KMeansInit} and is iterative. In each round, batches of samples are assigned to centroids
 * in parallel. The centroid assignment is performed using {@link #T#NearestNeighboursExact} in exact mode (i.e. brute-force) and
 * {@link #T#NearestNeighboursKDTree} in approximate (using an ensemble of kd-trees) mode. Once all samples are assigned new
 * centroids are calculated and the next round started. Data point pushing is performed using the same techniques as center point assignment.
 * <p>
 * This implementation is able to deal with larger-than-memory datasets by streaming the samples from disk using an appropriate
 * {@link DataSource}. The only requirement is that there is enough memory to hold all the centroids plus working memory for the batches
 * of samples being assigned.
 * <p>
 * Even in inexact mode this technique produces comparable results to an exact KMeans algorithm in much shorter time. 
 * 
 * @author Jonathon Hare (jsh2@ecs.soton.ac.uk)
 * @author Sina Samangooei (ss@ecs.soton.ac.uk)
 */
@Reference(
		type = ReferenceType.Inproceedings,
		author = { "Philbin, J.", "Chum, O.", "Isard, M.", "Sivic, J.", "Zisserman, A." },
		title = "Object Retrieval with Large Vocabularies and Fast Spatial Matching",
		year = "2007",
		booktitle = "CVPR",
		url = "http://marcade.robots.ox.ac.uk:8080/~vgg/publications/2007/Philbin07"
	)
public class Fast#T#KMeans implements SpatialClusterer<#T#CentroidsResult, #t#[]> {
	private static class AssignCentroidsJob implements Callable<Boolean> {
		private final DataSource<#t#[]> ds;
		private final int startRow;
		private final int stopRow;
		private final #T#NearestNeighbours nno;
		private final #r# [][] centroids_accum;
		private final int [] counts;
		private static int totalComplete = 0;

		public AssignCentroidsJob(DataSource<#t#[]> ds, int startRow, int stopRow, #T#NearestNeighbours nno, #r# [][] centroids_accum, int [] counts) {
			this.ds = ds; 
			this.startRow = startRow;
			this.stopRow = stopRow;
			this.nno = nno;
			this.centroids_accum = centroids_accum;
			this.counts = counts;
		}
		
		@Override
		public Boolean call() {
			try {
				int D = nno.numDimensions();

				#t# [][] points = new #t#[stopRow-startRow][D]; 
				ds.getData(startRow, stopRow, points);

				int [] argmins = new int[points.length];
				#r# [] mins = new #r#[points.length];

				nno.searchNN(points, argmins, mins);

				synchronized(centroids_accum){
					for (int i=0; i < points.length; ++i) {
						int k = argmins[i];
						for (int d=0; d < D; ++d) {
							centroids_accum[k][d] += points[i][d];
						}
						counts[k] += 1;
					}
					totalComplete += 1;
				}
			} catch(Exception e) {
				e.printStackTrace();
			}
			return true;
		}
	}
	
	private static class Result extends #T#CentroidsResult implements #T#NearestNeighboursProvider {
		protected #T#NearestNeighbours nn;
		
		@Override
		public HardAssigner<#t#[], ?, ?> defaultHardAssigner() {
			if (nn instanceof #T#NearestNeighboursExact)
				return new Exact#T#Assigner(this);
		
			return new Approximate#T#EuclideanAssigner(this);
		}
		
		@Override
		public #T#NearestNeighbours getNearestNeighbours() {
			return nn;
		}
	} 
	
	private Fast#T#KMeansInit init = new Fast#T#KMeansInit.RANDOM(); 
	private final KMeansConfiguration conf;
	private Random rng = new Random();
	
	/**
	 * Using data with M elements create K clusters. Whether the searching/clustering strategy should be exact is specified as are ntrees and nchecks (which
	 * are ignored if exact is true). The number of simultaneous threads during the training phase can also be specified.
	 *
	 * @param M number of elements in the data points. Default iterations and block size is used.
	 * @param K number of clusters to be found
	 * @param exact exact mode
	 * @param ntrees number of trees (ignored in exact mode)
	 * @param nchecks number of checks per tree (ignored in exact mode)
	 * @param nThreads number of parallel threads
	 */
	public Fast#T#KMeans(int M, int K, boolean exact, int ntrees, int nchecks, int nThreads) {
		this(M, K, exact, ntrees, nchecks, KMeansConfiguration.DEFAULT_BLOCK_SIZE, KMeansConfiguration.DEFAULT_NITERS, nThreads);
	}
	
	/**
	 * Using data with M elements create K clusters. Whether the searching/clustering strategy should be exact is specified. Defaults are used for all
	 * other parameters.
	 *
	 * @param M number of elements in the data points
	 * @param K number of clusters to be found
	 * @param exact exact mode
	 */
	public Fast#T#KMeans(int M, int K, boolean exact) {
		this(M, K, exact, KMeansConfiguration.DEFAULT_NTREES, KMeansConfiguration.DEFAULT_NCHECKS, 
				KMeansConfiguration.DEFAULT_BLOCK_SIZE, KMeansConfiguration.DEFAULT_NITERS, Runtime.getRuntime().availableProcessors());
	}
	
	/**
	 * Using data with M elements create K clusters. Whether the searching/clustering strategy should be exact is specified. The number of iterations
	 * during training can also be specified. All other parameters are default.
	 * 
	 * @param M number of elements in the data points. Default iterations and block size is used.
	 * @param K number of clusters to be found
	 * @param exact exact mode
	 * @param niters number of iterations
	 */
	public Fast#T#KMeans(int M, int K, boolean exact, int niters) {
		this( M, K,
				exact,
				KMeansConfiguration.DEFAULT_NTREES,
				KMeansConfiguration.DEFAULT_NCHECKS,
				KMeansConfiguration.DEFAULT_BLOCK_SIZE,
				niters,
				Runtime.getRuntime().availableProcessors()
		);
	}
	
	/**
	 * Using data with M elements create K clusters. Whether the searching/clustering strategy should be exact is specified as are ntrees and nchecks (which
	 * are ignored if exact is true). The number of simultaneous threads during the training phase can also be specified.
	 *
	 * @param M number of elements in the data points. Default iterations and block size is used.
	 * @param K number of clusters to be found
	 * @param exact exact mode
	 * @param ntrees number of trees (ignored in exact mode)
	 * @param nchecks number of checks per tree (ignored in exact mode)
	 * @param nThreads number of parallel threads
	 * @param block_size number of samples per parallel thread
	 * @param niters number of training iterations
	 */
	public Fast#T#KMeans(int M, int K, boolean exact, int ntrees, int nchecks, int block_size, int niters, int nThreads) {
		conf = new KMeansConfiguration(M, K, exact, ntrees, nchecks, block_size, niters, nThreads);
	}
	
	/**
	 * Construct the clusterer with the the given configuration.
	 * 
	 * @param conf The configuration.
	 */
	public Fast#T#KMeans(KMeansConfiguration conf) {
		this.conf = conf;
	}
	
	/**
	 * A completely default Fast#T#KMeans used primarily as a convenience function for reading.
	 */
	public Fast#T#KMeans() {
		this(0, 0, false, KMeansConfiguration.DEFAULT_NTREES, KMeansConfiguration.DEFAULT_NCHECKS, 
				KMeansConfiguration.DEFAULT_BLOCK_SIZE, KMeansConfiguration.DEFAULT_NITERS, Runtime.getRuntime().availableProcessors());
	}
	
	/**
	 * @return the init algorithm being used
	 */
	public Fast#T#KMeansInit getInit() {
		return init;
	}

	/**
	 * @param init the init algorithm to be used
	 */
	public void setInit(Fast#T#KMeansInit init) {
		this.init = init;
	}
	
	/**
	 * @param seed the random seed for init random sample selection, no seed if seed < -1
	 */
	public void seed(long seed) {
		if(seed < 0)
			this.rng = new Random();
		else
			this.rng = new Random(seed);
	}
		
	@Override
	public #T#CentroidsResult cluster(#t#[][] data) {
		DataSource<#t#[]> ds = new #T#ArrayBackedDataSource(data, rng);
		
		try {
			Result result = cluster(ds, conf.K);
			if (conf.exact) {
				result.nn = new #T#NearestNeighboursExact(result.centroids);
			} else {
				result.nn = new #T#NearestNeighboursKDTree(result.centroids, conf.ntrees, conf.nchecks);
			}
			
			return result;
		} catch (Exception e) {
			throw new RuntimeException(e);
		}
	}
	
	/**
	 * Initiate clustering with the given data and number of clusters.
	 * Internally this method constructs the array to hold the centroids 
	 * and calls {@link #cluster(DataSource, #t# [][])}.
	 *
	 * @param data data source to cluster with
	 * @param K number of clusters to find
	 * @return cluster centroids
	 */
	protected Result cluster(DataSource<#t#[]> data, int K) throws Exception {
		int D = data.numDimensions();
		
		Result result = new Result();
		result.centroids = new #t#[K][D];
	
		init.initFastKMeans(data, result.centroids);
	
		cluster(data, result);

		return result;
	}
	
	/**
	 * Main clustering algorithm. A number of threads as specified are started each containing an assignment job and a reference to
	 * the same set of #T#NearestNeighbours object (Exact or KDTree). Each thread is added to a job pool and started in parallel. 
	 * A single accumulator is shared between all threads and locked on update.
	 * @param data the data to be clustered
	 * @param centroids the centroids to be found
	 */
	protected void cluster(DataSource<#t#[]> data, Result result) throws Exception {
		final #t#[][] centroids = result.centroids;
		final int K = centroids.length;
		final int D = centroids[0].length;
		final int N = data.numRows();
		#r# [][] centroids_accum = new #r#[K][D];
		int [] new_counts = new int[K];

		ExecutorService service = null; 
		try {
			service = Executors.newFixedThreadPool(conf.nThreads);

			for (int i=0; i<conf.niters; i++) {
				for (int j=0; j<K; j++) Arrays.fill(centroids_accum[j], 0);
				Arrays.fill(new_counts, 0);

				#T#NearestNeighbours nno;
				if (!conf.exact)
					nno = new #T#NearestNeighboursKDTree(centroids, conf.ntrees, conf.nchecks);
				else
					nno = new #T#NearestNeighboursExact(centroids);

				List<AssignCentroidsJob> jobs = new ArrayList<AssignCentroidsJob>();
				for (int bl = 0; bl < N; bl += conf.block_size) {
					int br = Math.min(bl + conf.block_size, N);
					jobs.add(new AssignCentroidsJob(data, bl, br, nno, centroids_accum, new_counts));
				}

				service.invokeAll(jobs);

				for (int k=0; k < K; ++k) {
					if (new_counts[k] == 0) {
						// If there's an empty cluster we replace it with a random point.
						new_counts[k] = 1;

						#t# [][] rnd = new #t#[][] {centroids[k]};
						data.getRandomRows(rnd);
					} else {
						for (int d=0; d < D; ++d) {
							centroids[k][d] = (#t#)((#r#)round#R#((double)centroids_accum[k][d] / (double)new_counts[k]));
						}
					}
				}
			} 
		} finally {
			if (service != null) service.shutdownNow();
		}
	}
	
	protected float roundFloat(double value) { return (float) value; }
	protected double roundDouble(double value) { return value; }
	protected long roundLong(double value) { return (long)Math.round(value); }
	protected int roundInt(double value) { return (int)Math.round(value); }
	
	@Override
	public #T#CentroidsResult cluster(DataSource<#t#[]> ds) {
		try {
			Result result = cluster(ds, conf.K);
			
			if (conf.exact) {
				result.nn = new #T#NearestNeighboursExact(result.centroids);
			} else {
				result.nn = new #T#NearestNeighboursKDTree(result.centroids, conf.ntrees, conf.nchecks);
			}
			
			return result;
		} catch (Exception e) {
			throw new RuntimeException(e);
		}
	}
}
